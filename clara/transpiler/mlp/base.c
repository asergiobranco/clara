#include <stdio.h>
#include <math.h>

#define N_LAYERS 3
#define N_CLASSES 3
#define N_FEATURES 13

#define RELU

int networks_len[N_LAYERS] = {N_FEATURES, 30, N_CLASSES};

double sample[N_FEATURES] = {14.23, 1.71, 2.43, 15.6, 127.0, 2.8, 3.06, 0.28, 2.29, 5.64, 1.04, 3.92, 1065.0};
double network1[30] = {0};
double network2[N_CLASSES] = {0};

double * networks[N_LAYERS] = {sample, network1, network2};

double bias1[] = {-0.29045825, -0.07750775, -0.18021371, -0.30399845, -0.03993792,
        -0.29757603,  0.31533154,  0.30443593, -0.02097627,  0.01836169,
        -0.09099123, -0.39671295,  0.1845969 , -0.00827722,  0.18246034,
        -0.05701737, -0.30050842, -0.0156017 , -0.03848762, -0.06923781,
        -0.2107576 ,  0.19941405,  0.24047497,  0.25307678, -0.3130473 ,
        -0.06983881, -0.09649524,  0.3124188 , -0.19093008,  0.09622387};

double bias2[] = {0.01429985, -0.12878698,  0.3401578};

double * bias_networks[N_LAYERS-1] = {bias1, bias2};

double weights1[390] = {0.3424887578609592,-0.030320552988383705,-0.35275949937355655,0.3376359866245183,-0.04724110402073436,0.04683967383701414,-0.20658789118854773,0.31934561587413096,0.041704961624253904,0.1353592041798224,-0.3775271489084002,0.03704748915051143,-0.13378675792237438,0.12680555544584482,-0.06286785043198892,-0.009521215789308536,0.17551061566519124,-0.032110883557832086,-0.17954074965638342,-0.15289184785064958,0.0008064189767481912,0.1832449695048541,0.03809773570408477,0.1366998362562674,-0.14935146915321204,0.12814128797609448,0.2762653790115032,-0.07560458855428975,-0.12975373080370162,0.29576539218842235,0.11682744685202712,0.033894363685598394,-0.3020008561727864,0.21248432777541026,0.0006136360269959569,-0.09328527063806549,-0.1555210989506106,0.2942064004717449,0.10680028467415527,-0.029459564517262355,-0.07683185296396539,-0.36567708561386725,0.14957562305839792,-0.14701774700695713,0.025403311256158592,0.004425193859737759,-0.02675221631355986,0.022859616738777015,0.1357048060278993,0.10894311429647746,0.18813770201959187,-0.05831834247009901,0.20499953920019187,-0.3919334710479651,-0.13659685792867032,0.06518601413433461,-0.19837144531969003,0.26602806231785436,0.2775968550285566,0.34646846834811634,-0.36926769810581683,0.31923607099540113,0.3100302085661932,-0.2661493968214526,0.1635651179342635,-0.09812541689992214,0.3249727349830408,0.2793766277361022,-0.0032243556914499055,0.14352679004016414,0.3608469248740563,-0.21315360842258052,0.08852156457898526,-0.10715937870218191,0.003955626778883975,-0.009049973141047735,0.12510780981994848,0.2053157391730806,0.16305210991951347,-0.07569652450255912,-0.11233007869742082,0.33376149862806564,0.0975983982696833,-0.18139288908110993,0.028913580776950117,0.037335895606971446,0.3691248206327491,-0.2687608280396446,0.12552795530853403,-0.1075064632141132,0.19209962450281348,-0.07477182429444934,0.06265981562987502,-0.35010060612483984,-0.014726255097738124,0.1904496579319091,-0.1829839427014918,-0.0009042512887054581,-0.0242258756282866,0.12861759362223155,0.1928427423034624,-0.02442991889057572,-0.22389989728159435,0.02829027164041637,0.21608891549727835,0.1944584621613796,-0.17487545264872006,-0.05147648450415533,-0.00023121724885638453,-0.005114732997389102,-0.05329897436468752,-0.2915669886459316,-0.3271818908717009,-0.021579921441848848,0.05326708404702292,-0.149922504431355,-0.11683154925672516,0.10124617540918447,0.11534667284292928,0.3461681749579178,-0.0022046449383555803,0.31551077109104525,-0.11797057915888441,-0.36256371846829955,-0.07853413877261069,-8.291161273790633e-05,-0.20732723675360432,0.04053518176807688,-0.041935799352024836,-0.03941265210603535,-0.24438367350695073,-0.228985531700315,-0.19104923510548344,-0.18758894580540367,-0.017605385865973284,-0.03604594195057566,0.04349601511413607,-0.06255929379786257,-0.0005548108838088173,-0.08000068016457038,0.05998341344772246,-0.346884794847064,0.1321765175419309,-0.20919348039027563,0.02169792507865621,-0.29069693308595296,0.012821472942865422,0.18460277325927232,-0.003129388236364969,0.037941441834071186,0.16653974724742146,0.2706295209444418,0.14259107696273013,0.19234944626841166,0.2248237239983089,0.19068817629102824,-0.25980821747819227,-0.1368323995937096,0.225039424441381,0.042220309305914194,0.004100936862302702,0.07704163768708389,0.17102401099163306,-0.092927549058342,0.1512782187367585,0.0001839865165205374,0.19826069887092893,0.1308060809477725,0.18620130030432705,0.013865595015769913,-0.05494485545018337,-0.3840559283634984,-0.0021877651323166615,0.0030691283345836403,0.007168905254193641,0.08891355150115267,0.18737095738260348,-0.19215598017212146,0.059545384232481374,-0.30926675249173935,-0.21099862281664805,-0.239912501359467,0.13061984444989183,-0.08882571813867195,0.001828559841333648,-2.2070033584631035e-05,-0.26884952499893827,0.16529373938101788,-0.08650918657000291,-7.30493940916128e-05,0.05364625088228259,0.23699280240257603,0.08594582957036845,0.18182842709292768,0.018941223629255825,0.17787198557480996,0.13545073471106925,0.00014668105880172912,0.04164163487535755,0.1172978022601324,-0.07805474527582733,0.00944296194260491,-0.1864000403584983,0.3482569806519955,0.0711521546146183,-0.42928414376570356,-0.1731200202105121,0.1965313530300055,-0.2175552216041635,-0.17888848285623604,-0.3235469286826001,-0.15115095709236434,-0.031152393670360483,-0.30329456672662225,-7.178598139413141e-05,-0.2222945812985375,0.03651383638037417,-0.21702572920297467,0.18484258116766847,0.012640785778347884,0.18486819116806247,0.07673062998849194,-0.11977890940444315,3.100671329646607e-05,0.15521219866898092,0.046140193548626265,-0.25554001873760207,-0.16117627215143934,-0.17187447287246402,0.1949693787665642,-0.06544234230768768,0.1343413167874747,0.1642410545951622,-0.3227005027073566,-0.025637754809685716,0.2814507639514524,-0.16481726614062317,-0.054373015228505815,-0.22207156178327075,-0.23080388327313622,-0.09385394472504983,0.4491068975738993,-0.05715579781071283,-0.41091440016951347,-0.03436660065209188,-0.18293561582672238,0.059327750661615775,-0.08362711106450707,-0.2168212445304279,-0.06849330696998943,-0.25010088959642857,-0.2231043097407508,-0.0008263599000625804,-0.10077765390907677,0.003523259182599275,-0.04873164908220299,0.12360489071170626,0.22132270215122388,-0.11374049641281166,0.006400808189396439,-0.06943745412778707,-0.2820840392234809,0.0962678656129651,0.17798593892671585,0.19745975676353353,0.1284442371922087,-0.039840499857429275,0.0250117005029759,0.09880017004076122,0.08971506885725576,-0.22672436569062915,0.025804982650870664,0.19121656514469684,0.11891508714309676,0.19848516862108684,0.176148429795924,0.013616788459579194,0.29186245199023575,-0.19758685502435003,-0.1718131723361457,-0.31946069495386914,-0.014507572244202828,0.102587478974096,0.13499860070789738,0.0008448249421612317,0.013559321495103704,0.225366560485788,0.05308763326605398,0.18061422868044405,-0.0005369913287447501,-0.014573510244610396,0.24379877084892657,0.20725851612385962,-0.3787714143624147,0.007523837458442051,0.3197224661744135,-0.22341835995978296,0.3239298815798508,0.23971643899622516,0.19006280795967495,-0.23358334007610285,0.08758239933009594,-0.25099743371824934,-0.3176093750914766,0.1332315941056187,0.0767599361837371,-0.28722465110454043,0.19956611109191502,-0.12378285861932856,-0.045465846603331334,0.2219073755393045,0.12848960377842492,-0.10213204165854542,0.16942662719343757,0.040364977953130945,0.0038221649859010555,0.18707090936837903,-0.162568674887315,0.13363806145588256,0.006905127677321849,-0.13941657709433816,-0.06057975814353826,-0.18548185613756402,0.06261176890605223,-0.10517189038165219,0.044136740100129364,0.017232373302407226,-0.1208686906353111,0.05388945514485687,-0.4046847162329851,0.27980661094157605,0.16990397610510594,0.35491391595005445,0.05868643984707794,-0.06596489937420855,0.14087327363888877,-0.12121056900292237,0.10769483159341317,-0.09329970980001945,0.13039619377049608,0.11814561789014129,-0.07045814422259093,0.14743670204300782,0.014326191219765394,0.09598074567615268,-0.022695321952521164,0.11831903558478328,-0.030074642370486192,0.09395471477643963,-0.030060228442613617,-0.22001851986492685,0.16100845952355472,0.4003814918462899,0.12791313126347514,0.07694782516900762,0.17385418337054923,0.003881025008375155,-0.3437613839115921,-0.07690443728770881,-0.30526490544794244,0.1662890142631483,-0.019598174394324142,0.31754334766825276,0.23715363471631326,-0.02906659309566,-0.14453626689174637,0.12385116871997588,0.3099101153962052,-0.018058812034627142,-0.060732750566470435,0.08565495942347587,0.037476796847119256,-0.1592576399475105,-0.019902743161428864,-0.04864094121040307,-0.026386677601675842,0.09294832354506884,-0.0011474376686544066,-0.2115210316710016,-0.004258843819165976,-0.2220302874698077,0.12976090564780712,0.06569364211604214,0.06624117882734265,-0.16499180445652095,0.2811355869319296,0.02188853539252754,-0.013248607839852397,0.06024095683733621,0.2783792946271148};
double weights2[90] = {0.09902314615533729,0.23600622490397288,0.026390344725160796,-0.28687746059847846,0.26580299004186564,0.045319363062142855,0.016653518905225612,0.2815359461892625,-0.38556817067740595,0.21969713246865538,0.12060972969601969,0.3836006975922302,0.042715381017894065,0.08373620132421283,0.13982648712783818,0.16941460135735043,-0.028611130979034997,0.07140612329339034,0.28660881469312016,0.060674300964485214,0.3597666931467466,0.0952305807818052,0.3115600461657558,0.054965540595884155,0.10288519193260992,0.0017194550449827115,0.03397372251996602,0.003620234345324883,-0.10007607814153596,-0.008155556448708213,-0.008692453380096448,0.11979077935107861,-0.20989246401441924,-0.2718817579164582,-0.16622292282438492,0.21278367012476912,-0.005580256819623291,0.018185132779997643,0.1792054581198955,0.003678409275519523,-0.0653429619363361,0.01669318622282376,0.13577135293939702,0.00024230458869253755,-0.049849009979589604,0.059960284487977696,0.19662603861777814,-0.12398653611343687,0.42429804002842236,-0.4720496290591586,0.25545294661031676,0.06781600426009624,-0.10364083258711637,-0.10380405404979613,0.1278788775225159,0.25724016478061185,-0.02130390681788691,0.06876629608512108,-0.21942259951774704,-0.19440264543559188,-0.1282886681403572,-0.13704198930197978,-0.09561564723192384,0.1584524058911214,0.18647025972920736,0.11367611846531411,0.0936265128519464,0.14201134257578238,-0.4357348722000669,-0.16024551345558954,-0.006314201943277054,-0.27646490595378087,-0.0013679766741699574,0.030738336219291416,0.07749417996920928,-0.07325202323402202,-0.0787197267094432,0.28084511933293393,-0.07889859139644108,-0.39809124542807217,0.3228259554934379,-0.27484279578566634,-0.11489378238495257,0.2944919503097812,0.24908369173167422,0.2755653370135546,0.02673455726816874,0.000929766422205897,-0.24266244910001492,0.2910310530493475};

double * weights_networks[N_LAYERS-1] = {weights1, weights2};

#ifdef IDENTITY
double identity(double neuron){
    return neuron;
}
#define ACTIVATION(...) identity(__VA_ARGS__)
#endif


#ifdef LOGISTIC
double logistic(double neuron){
  return 1 / (1+exp(-neuron));
}
#define ACTIVATION(...) logistic(__VA_ARGS__)
#endif

#ifdef RELU
double relu(double neuron){
  return (neuron > 0.0 ? neuron : 0.0);
}
#define ACTIVATION(...) relu(__VA_ARGS__)
#endif

#ifdef TANH
#define ACTIVATION(...) tanh(__VA_ARGS__)
#endif

double * softmax(double * neurons, int len){
    double sum = 0;
    int i = 0;
    for(i =0; i<len; i++){
        neurons[i] = exp(neurons[i]);
        sum += neurons[i];
    }

    for(i =0; i<len; i++){
        neurons[i] /= sum;
    }

    return neurons;
}

double * propagation(double * network, double * next_network, double * weights, double * bias, int network_len, int next_network_len, int layer_no){
  int i = 0, j = 0, w=0;
  for(i=0; i < next_network_len; i++){
      next_network[i] = bias[i];
  }

  for(i=0; i < next_network_len; i++){
    for(j = 0; j < network_len; j++){
        w = (next_network_len * j) + i;
      next_network[i] += network[j] * weights[w];
    }
      if(layer_no < (N_LAYERS-2)){
          next_network[i] = ACTIVATION(next_network[i]);
      }

  }



  return next_network;
}

double predict(double * sample){
  int i = 0;

  for(i = 0; i < N_LAYERS - 1; i++){
    propagation(networks[i], networks[i+1], weights_networks[i], bias_networks[i], networks_len[i], networks_len[i+1], i);
  }

    softmax(networks[N_LAYERS-1], networks_len[N_LAYERS-1]);


  for(i = 0; i < N_CLASSES; i++){
    printf("%f\n\n", networks[N_LAYERS-1][i]);
  }
    return 0.0;
}


int main(){
    predict(sample);
    return 0;
}
